---
language:
  - en
  - zh
license: other
tasks:
  - text-generation
studios:
  - baichuan-inc/Baichuan-13B-Chatdemo
---

<!-- markdownlint-disable first-line-h1 -->
<!-- markdownlint-disable html -->
<div align="center">
<h1>
  Baichuan 2
</h1>
</div>

<div align="center">
  <a href="https://github.com/baichuan-inc/Baichuan2" target="_blank">ğŸ¦‰GitHub</a> | 
  <a href="https://modelscope.cn/models/baichuan-inc/Baichuan-13B-Base/file/view/master/wechat.jpeg" target="_blank">ğŸ’¬WeChat</a> | 
  <a href="https://modelscope.cn/studios/baichuan-inc/Baichuan-13B-Chatdemo/summary" target="_blank">ğŸ¤–Demo</a> 
</div>
<div align="center">
ğŸš€ <a href="https://www.baichuan-ai.com/" target="_blank">ç™¾å·å¤§æ¨¡å‹åœ¨çº¿å¯¹è¯å¹³å°</a> å·²æ­£å¼å‘å…¬ä¼—å¼€æ”¾ ğŸ‰
</div>

# ç›®å½•

- [ğŸ“– æ¨¡å‹ä»‹ç»](#æ¨¡å‹ä»‹ç»)
- [âš™ï¸ å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [ğŸ“Š Benchmarkè¯„ä¼°](#è¯„ä¼°)
- [ğŸ“œ å£°æ˜ä¸åè®®](#å£°æ˜ä¸åè®®)

# æ¨¡å‹ä»‹ç»

- Baichuan 2 æ˜¯[ç™¾å·æ™ºèƒ½]æ¨å‡ºçš„**æ–°ä¸€ä»£å¼€æºå¤§è¯­è¨€æ¨¡å‹**ï¼Œé‡‡ç”¨ **2.6 ä¸‡äº¿**  Tokens çš„é«˜è´¨é‡è¯­æ–™è®­ç»ƒã€‚
- Baichuan 2 åœ¨å¤šä¸ªæƒå¨çš„ä¸­æ–‡ã€è‹±æ–‡å’Œå¤šè¯­è¨€çš„é€šç”¨ã€é¢†åŸŸ benchmark ä¸Šå–å¾—åŒå°ºå¯¸**æœ€ä½³**çš„æ•ˆæœã€‚
- æœ¬æ¬¡å‘å¸ƒåŒ…å«æœ‰ **7B**ã€**13B** çš„ **Base** å’Œ **Chat** ç‰ˆæœ¬ï¼Œå¹¶æä¾›äº† Chat ç‰ˆæœ¬çš„ **4bits é‡åŒ–**ã€‚
- æ‰€æœ‰ç‰ˆæœ¬å¯¹å­¦æœ¯ç ”ç©¶å®Œå…¨å¼€æ”¾ã€‚åŒæ—¶ï¼Œå¼€å‘è€…é€šè¿‡é‚®ä»¶ç”³è¯·å¹¶è·å¾—å®˜æ–¹å•†ç”¨è®¸å¯åï¼Œå³å¯**å…è´¹å•†ç”¨**ï¼Œè¯·å‚è€ƒ[åè®®](#åè®®)ç« èŠ‚ã€‚
- æ¬¢è¿é˜…è¯»æˆ‘ä»¬çš„æŠ€æœ¯æŠ¥å‘Š [Baichuan 2: Open Large-scale Language Models] è·å–æ›´å¤šä¿¡æ¯ã€‚

æœ¬æ¬¡å‘å¸ƒç‰ˆæœ¬å’Œä¸‹è½½é“¾æ¥è§ä¸‹è¡¨ï¼š

|     |          åŸºåº§æ¨¡å‹        |          å¯¹é½æ¨¡å‹        |       å¯¹é½æ¨¡å‹ 4bits é‡åŒ–        |
|:---:|:--------------------:|:--------------------:|:--------------------------:|
| 7B  | [Baichuan2-7B-Base]  | [Baichuan2-7B-Chat]  | [Baichuan2-7B-Chat-4bits]  |
| 13B | [Baichuan2-13B-Base] | [Baichuan2-13B-Chat] | [Baichuan2-13B-Chat-4bits] |

# å¿«é€Ÿå¼€å§‹

```python
import torch
from modelscope import snapshot_download, AutoModelForCausalLM, AutoTokenizer,GenerationConfig
model_dir = snapshot_download("baichuan-inc/Baichuan2-13B-Chat", revision='v1.0.2')
tokenizer = AutoTokenizer.from_pretrained(model_dir, device_map="auto", 
                              trust_remote_code=True, torch_dtype=torch.float16)
model = AutoModelForCausalLM.from_pretrained(model_dir, device_map="auto", 
                              trust_remote_code=True, torch_dtype=torch.float16)
model.generation_config = GenerationConfig.from_pretrained(model_dir)
messages = []
messages.append({"role": "user", "content": "è®²è§£ä¸€ä¸‹â€œæ¸©æ•…è€ŒçŸ¥æ–°â€"})
response = model.chat(tokenizer, messages)
print(response)
messages.append({'role': 'assistant', 'content': response})
messages.append({"role": "user", "content": "èƒŒè¯µä¸€ä¸‹å°†è¿›é…’"})
response = model.chat(tokenizer, messages)
print(response)
```
åœ¨é­”æ­ç¤¾åŒºçš„å…è´¹ç®—åŠ›ä¸Šï¼Œä¹Ÿå¯ä»¥é€šè¿‡é‡åŒ–çš„æ–¹å¼ä½¿ç”¨13Bå¯¹è¯æ¨¡å‹
```python
import torch
from modelscope import snapshot_download, AutoModelForCausalLM, AutoTokenizer,GenerationConfig
from transformers import BitsAndBytesConfig

quantization_config = BitsAndBytesConfig(
    False,
    True,
    bnb_4bit_compute_dtype=torch.bfloat16,
    bnb_4bit_quant_type='nf4',
    bnb_4bit_use_double_quant=True)
model_dir = snapshot_download("baichuan-inc/Baichuan2-13B-Chat", revision='v1.0.2')
tokenizer = AutoTokenizer.from_pretrained(model_dir, device_map="auto", 
                              trust_remote_code=True, torch_dtype=torch.float16)
model = AutoModelForCausalLM.from_pretrained(model_dir, device_map="auto", 
                              trust_remote_code=True, torch_dtype=torch.float16,
                              quantization_config=quantization_config)
model.generation_config = GenerationConfig.from_pretrained(model_dir)
messages = []
messages.append({"role": "user", "content": "è®²è§£ä¸€ä¸‹â€œæ¸©æ•…è€ŒçŸ¥æ–°â€"})
response = model.chat(tokenizer, messages)
print(response)
messages.append({'role': 'assistant', 'content': response})
messages.append({"role": "user", "content": "èƒŒè¯µä¸€ä¸‹å°†è¿›é…’"})
response = model.chat(tokenizer, messages)
print(response)
```
# Benchmark ç»“æœ

æˆ‘ä»¬åœ¨[é€šç”¨]ã€[æ³•å¾‹]ã€[åŒ»ç–—]ã€[æ•°å­¦]ã€[ä»£ç ]å’Œ[å¤šè¯­è¨€ç¿»è¯‘]å…­ä¸ªé¢†åŸŸçš„ä¸­è‹±æ–‡æƒå¨æ•°æ®é›†ä¸Šå¯¹æ¨¡å‹è¿›è¡Œäº†å¹¿æ³›æµ‹è¯•ï¼Œæ›´å¤šè¯¦ç»†æµ‹è¯„ç»“æœå¯æŸ¥çœ‹[GitHub]ã€‚

### 7B æ¨¡å‹ç»“æœ

|                         | **C-Eval** | **MMLU** | **CMMLU** | **Gaokao** | **AGIEval** | **BBH** |
|:-----------------------:|:----------:|:--------:|:---------:|:----------:|:-----------:|:-------:|
|                         |  5-shot    |  5-shot  |  5-shot   | 5-shot     | 5-shot      | 3-shot  |
|        **GPT-4**        | 68.40      | 83.93    | 70.33     | 66.15      | 63.27       | 75.12   |
|    **GPT-3.5 Turbo**    | 51.10      | 68.54    | 54.06     | 47.07      | 46.13       | 61.59   |
|      **LLaMA-7B**       | 27.10      | 35.10    | 26.75     | 27.81      | 28.17       | 32.38   |
|      **LLaMA2-7B**      | 28.90      | 45.73    | 31.38     | 25.97      | 26.53       | 39.16   |
|       **MPT-7B**        | 27.15      | 27.93    | 26.00     | 26.54      | 24.83       | 35.20   |
|      **Falcon-7B**      | 24.23      | 26.03    | 25.66     | 24.24      | 24.10       | 28.77   |
|     **ChatGLM2-6B**     | 50.20      | 45.90    | 49.00     | 49.44      | 45.28       | 31.65   |
|    **[Baichuan-7B]**    | 42.80      | 42.30    | 44.02     | 36.34      | 34.44       | 32.48   |
| **[Baichuan2-7B-Base]** | 54.00      | 54.16    | 57.07     | 47.47      | 42.73       | 41.56   |

### 13B æ¨¡å‹ç»“æœ

|                             | **C-Eval** | **MMLU** | **CMMLU** | **Gaokao** | **AGIEval** | **BBH** |
|:---------------------------:|:----------:|:--------:|:---------:|:----------:|:-----------:|:-------:|
|                             |  5-shot    |  5-shot  |  5-shot   | 5-shot     | 5-shot      | 3-shot  |
|          **GPT-4**          | 68.40      | 83.93    | 70.33     | 66.15      | 63.27       | 75.12   |
|      **GPT-3.5 Turbo**      | 51.10      | 68.54    | 54.06     | 47.07      | 46.13       | 61.59   |
|        **LLaMA-13B**        | 28.50      | 46.30    | 31.15     | 28.23      | 28.22       | 37.89   |
|       **LLaMA2-13B**        | 35.80      | 55.09    | 37.99     | 30.83      | 32.29       | 46.98   |
|       **Vicuna-13B**        | 32.80      | 52.00    | 36.28     | 30.11      | 31.55       | 43.04   |
| **Chinese-Alpaca-Plus-13B** | 38.80      | 43.90    | 33.43     | 34.78      | 35.46       | 28.94   |
|       **XVERSE-13B**        | 53.70      | 55.21    | 58.44     | 44.69      | 42.54       | 38.06   |
|  **[Baichuan-13B-Base]**    | 52.40      | 51.60    | 55.30     | 49.69      | 43.20       | 43.01   |
|  **[Baichuan2-13B-Base]**   | 58.10      | 59.17    | 61.97     | 54.33      | 48.17       | 48.78   |


## è®­ç»ƒè¿‡ç¨‹æ¨¡å‹

é™¤äº†è®­ç»ƒäº† 2.6 ä¸‡äº¿ Tokens çš„ [Baichuan2-7B-Base] æ¨¡å‹ï¼Œæˆ‘ä»¬è¿˜æä¾›äº†åœ¨æ­¤ä¹‹å‰çš„å¦å¤– 11 ä¸ªä¸­é—´è¿‡ç¨‹çš„æ¨¡å‹ï¼ˆåˆ†åˆ«å¯¹åº”è®­ç»ƒäº†çº¦ 0.2 ~ 2.4 ä¸‡äº¿ Tokensï¼‰ä¾›ç¤¾åŒºç ”ç©¶ä½¿ç”¨ï¼ˆ[è®­ç»ƒè¿‡ç¨‹checkpointä¸‹è½½]ï¼‰ã€‚ä¸‹å›¾ç»™å‡ºäº†è¿™äº› checkpoints åœ¨ C-Evalã€MMLUã€CMMLU ä¸‰ä¸ª benchmark ä¸Šçš„æ•ˆæœå˜åŒ–ï¼š

![checkpoint](https://modelscope.cn/api/v1/models/baichuan-inc/Baichuan2-7B-Base/repo?Revision=master&FilePath=media/checkpoints.jpeg&View=true)

# å£°æ˜ä¸åè®®

## å£°æ˜

æˆ‘ä»¬åœ¨æ­¤å£°æ˜ï¼Œæˆ‘ä»¬çš„å¼€å‘å›¢é˜Ÿå¹¶æœªåŸºäº Baichuan 2 æ¨¡å‹å¼€å‘ä»»ä½•åº”ç”¨ï¼Œæ— è®ºæ˜¯åœ¨ iOSã€Androidã€ç½‘é¡µæˆ–ä»»ä½•å…¶ä»–å¹³å°ã€‚æˆ‘ä»¬å¼ºçƒˆå‘¼åæ‰€æœ‰ä½¿ç”¨è€…ï¼Œä¸è¦åˆ©ç”¨
Baichuan 2 æ¨¡å‹è¿›è¡Œä»»ä½•å±å®³å›½å®¶ç¤¾ä¼šå®‰å…¨æˆ–è¿æ³•çš„æ´»åŠ¨ã€‚å¦å¤–ï¼Œæˆ‘ä»¬ä¹Ÿè¦æ±‚ä½¿ç”¨è€…ä¸è¦å°† Baichuan 2
æ¨¡å‹ç”¨äºæœªç»é€‚å½“å®‰å…¨å®¡æŸ¥å’Œå¤‡æ¡ˆçš„äº’è”ç½‘æœåŠ¡ã€‚æˆ‘ä»¬å¸Œæœ›æ‰€æœ‰çš„ä½¿ç”¨è€…éƒ½èƒ½éµå®ˆè¿™ä¸ªåŸåˆ™ï¼Œç¡®ä¿ç§‘æŠ€çš„å‘å±•èƒ½åœ¨è§„èŒƒå’Œåˆæ³•çš„ç¯å¢ƒä¸‹è¿›è¡Œã€‚

æˆ‘ä»¬å·²ç»å°½æˆ‘ä»¬æ‰€èƒ½ï¼Œæ¥ç¡®ä¿æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨çš„æ•°æ®çš„åˆè§„æ€§ã€‚ç„¶è€Œï¼Œå°½ç®¡æˆ‘ä»¬å·²ç»åšå‡ºäº†å·¨å¤§çš„åŠªåŠ›ï¼Œä½†ç”±äºæ¨¡å‹å’Œæ•°æ®çš„å¤æ‚æ€§ï¼Œä»æœ‰å¯èƒ½å­˜åœ¨ä¸€äº›æ— æ³•é¢„è§çš„é—®é¢˜ã€‚å› æ­¤ï¼Œå¦‚æœç”±äºä½¿ç”¨
Baichuan 2 å¼€æºæ¨¡å‹è€Œå¯¼è‡´çš„ä»»ä½•é—®é¢˜ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºæ•°æ®å®‰å…¨é—®é¢˜ã€å…¬å…±èˆ†è®ºé£é™©ï¼Œæˆ–æ¨¡å‹è¢«è¯¯å¯¼ã€æ»¥ç”¨ã€ä¼ æ’­æˆ–ä¸å½“åˆ©ç”¨æ‰€å¸¦æ¥çš„ä»»ä½•é£é™©å’Œé—®é¢˜ï¼Œæˆ‘ä»¬å°†ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚

## åè®®

* Baichuan 2 æ¨¡å‹çš„ç¤¾åŒºä½¿ç”¨éœ€éµå¾ª[ã€ŠBaichuan 2 æ¨¡å‹ç¤¾åŒºè®¸å¯åè®®ã€‹]ã€‚
* Baichuan 2 æ”¯æŒå•†ç”¨ï¼Œå¦‚æœå°† Baichuan 2 æ¨¡å‹æˆ–å…¶è¡ç”Ÿå“ç”¨ä½œå•†ä¸šç”¨é€”ï¼Œè¯·æ‚¨æŒ‰ç…§å¦‚ä¸‹æ–¹å¼è”ç³»è®¸å¯æ–¹ï¼Œä»¥è¿›è¡Œç™»è®°å¹¶å‘è®¸å¯æ–¹ç”³è¯·ä¹¦é¢æˆæƒï¼šè”ç³»é‚®ç®± [opensource@baichuan-inc.com]ã€‚

[GitHub]:https://github.com/baichuan-inc/Baichuan2
[Baichuan2]:https://github.com/baichuan-inc/Baichuan2

[Baichuan-7B]:https://modelscope.cn/models/baichuan-inc/baichuan-7B/summary
[Baichuan2-7B-Base]:https://modelscope.cn/models/baichuan-inc/Baichuan2-7B-Base/summary
[Baichuan2-7B-Chat]:https://modelscope.cn/models/baichuan-inc/Baichuan2-7B-Chat/summary
[Baichuan2-7B-Chat-4bits]:https://modelscope.cn/models/baichuan-inc/Baichuan2-7B-Chat-4bits/summary
[Baichuan-13B-Base]:https://modelscope.cn/models/baichuan-inc/Baichuan-13B-Base/summary
[Baichuan2-13B-Base]:https://modelscope.cn/models/baichuan-inc/Baichuan2-13B-Base/summary
[Baichuan2-13B-Chat]:https://modelscope.cn/models/baichuan-inc/Baichuan2-13B-Chat/summary
[Baichuan2-13B-Chat-4bits]:https://modelscope.cn/models/baichuan-inc/Baichuan2-13B-Chat-4bits/summary

[é€šç”¨]:https://github.com/baichuan-inc/Baichuan2#%E9%80%9A%E7%94%A8%E9%A2%86%E5%9F%9F
[æ³•å¾‹]:https://github.com/baichuan-inc/Baichuan2#%E6%B3%95%E5%BE%8B%E5%8C%BB%E7%96%97
[åŒ»ç–—]:https://github.com/baichuan-inc/Baichuan2#%E6%B3%95%E5%BE%8B%E5%8C%BB%E7%96%97
[æ•°å­¦]:https://github.com/baichuan-inc/Baichuan2#%E6%95%B0%E5%AD%A6%E4%BB%A3%E7%A0%81
[ä»£ç ]:https://github.com/baichuan-inc/Baichuan2#%E6%95%B0%E5%AD%A6%E4%BB%A3%E7%A0%81
[å¤šè¯­è¨€ç¿»è¯‘]:https://github.com/baichuan-inc/Baichuan2#%E5%A4%9A%E8%AF%AD%E8%A8%80%E7%BF%BB%E8%AF%91

[ã€ŠBaichuan 2 æ¨¡å‹ç¤¾åŒºè®¸å¯åè®®ã€‹]:https://huggingface.co/baichuan-inc/Baichuan2-7B-Base/blob/main/Baichuan2%20%E6%A8%A1%E5%9E%8B%E7%A4%BE%E5%8C%BA%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf

[é‚®ä»¶ç”³è¯·]: mailto:opensource@baichuan-inc.com
[Email]: mailto:opensource@baichuan-inc.com
[opensource@baichuan-inc.com]: mailto:opensource@baichuan-inc.com
[è®­ç»ƒè¿‡ç¨‹checkpointä¸‹è½½]: https://huggingface.co/baichuan-inc/Baichuan2-7B-Intermediate-Checkpoints
[ç™¾å·æ™ºèƒ½]: https://www.baichuan-ai.com
[Baichuan 2: Open Large-scale Language Models]:https://cdn.baichuan-ai.com/paper/Baichuan2-technical-report.pdf